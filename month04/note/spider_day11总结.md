# 1、什么是爬虫
  爬虫是请求网站并提取数据的自动化程序
​
# 2、robots协议是什么
  爬虫协议或机器人协议,网站通过robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取
​
# 3、爬虫的基本流程
  1、请求得到响应
  2、解析
  3、保存数据
​
# 4、请求
  1、urllib
  2、requests
  3、scrapy
​
# 5、解析
  1、re正则表达式
  2、lxml+xpath解析
  3、json解析模块
​
# 6、selenium+browser
​
# 7、常见反爬策略
  1、Headers : 最基本的反爬手段，一般被关注的变量是UserAgent和Referer，可以考虑使用浏览器中
  2、UA ： 建立User-Agent池,每次访问页面随机切换
  3、拉黑高频访问IP
     数据量大用代理IP池伪装成多个访问者,也可控制爬取速度
  4、Cookies
     建立有效的cookie池，每次访问随机切换
  5、验证码
    验证码数量较少可人工填写
    图形验证码可使用tesseract识别
    其他情况只能在线打码、人工打码和训练机器学习模型
  6、动态生成
    一般由js动态生成的数据都是向特定的地址发get请求得到的，返回的一般是json
  7、签名及js加密
    一般为本地JS加密,查找本地JS文件,分析,或者使用execjs模块执行JS
  8、js调整页面结构
  9、js在响应中指向新的地址
​
# 8、scrapy框架的运行机制
​
# 9、分布式爬虫的原理
  多台主机共享一个爬取队列

